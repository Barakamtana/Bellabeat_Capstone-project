---
title: "Bellabeat_Capstone_Project"
author: "Baraka Mtana"
date: "`r Sys.Date()`"
output:
  pdf_document:
    keep_tex: true
    number_sections: true
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Set up environment
# import libraries
library(tidyverse)
# install.packages("lubridate")
library(lubridate)
library(ggplot2)
library(dplyr)

```


```{r}
# get and print working directory
currentDir <- getwd() 
print(currentDir)

# list file in the working DIR
list.files(currentDir)

# we are interested in the csv files in 'mturkfitbit_export_3.12.16-4.11.16'
# and 'Fitabase Data 3.12.16-4.11.16'
csv_files_Dir <- file.path(
  currentDir, 'mturkfitbit_export_3.12.16-4.11.16', 'Fitabase Data 3.12.16-4.11.16'
)

csv_files <- list.files(csv_files_Dir)
len_cvs = length(csv_files)

# csv_files <- list.files(csv_files_Dir, pattern = "\\.csv$", full.names = TRUE)
# print(csv_files)
```


```{r}
# Initialize an empty list to store data frames
dfs <- list()


for (file in csv_files) {
  
  print(paste("Working on", file))
  
  # create df names
  # split the file name str character
  df_name <- strsplit(file, split = '\\.')[[1]] #Access the first and only string
  
  # get the first part of the string character which is basically the name 
  # without the csv extension
  df_name <- df_name[1]
  
  # concatenate the df_name with df
  df_name <- paste0(df_name, "_df") # Use paste0 for no space between parts
  
  # create full path for each file so that we can import them
  filepath <- file.path(csv_files_Dir, file)
  
  # read csv 
  df <- read.csv((filepath))
  
  # append dfs and their names
  dfs[[df_name]] <- df  # Store the data frame in the list, keyed by file path

}
```


```{r}
# Confirm that all df were read successfully
if (len_cvs == length(dfs)) {
  print("All files read successfully")
} else {
  print("Some files were not read correctly")
}

```
```{r}
print(names(dfs))
```


```{r}
# Here we'll write function we'll reuse

# Check for missing values
missing_value <- function(df){
  print(paste("Count of total missing values", sum(is.na(df))))
}


# get number of unique values
unique_value <- function(df, column_of_interest) {
  #get the unique values
  uniques <- unique(df[[column_of_interest]])
  
  # Get the unique values from the specified column
  n_unique <- length(uniques)
  
  print(paste(column_of_interest, "has",  n_unique, "values"))
  
}



N_unique_char <- function(df, column_of_interest){
  # Initialize/ pre-allocate a numeric vector of a specific length, initialized with   zeros
  n_char <- numeric(nrow(df)) 
  
  for (i in seq_along(df[[column_of_interest]])){
    n_char[i] <- nchar(df[[column_of_interest]][i])
  }
  
  # get the number of unique characters
  character_lens <- unique(n_char)
  
  return(character_lens)
}
  

# change column to datetime
change_to_date <- function(df, column_of_interest){
  df[[column_of_interest]] <- 
      as.POSIXct(
      df[[column_of_interest]],
      format="%m/%d/%Y" ,tz=Sys.timezone()
      )
  # confirm the datatype of the column of interest
  print(paste(column_of_interest, "has" ,class(df[[column_of_interest]]) , "datatype"))
  
  print(head(df[column_of_interest], 10))
  
  
  return(df)
  
}

# Check if the columns are identical
identical_columns <- function(df, col1, col2){
  if (identical(df[[col1]], df[[col2]])) {
    print("The columns are identical.")
  } else {
    print("The columns are NOT identical.")
  } 
}


# calculate averages
averages <- function(df){
  averages_per_athlete <- df %>%
    group_by(Id)  %>%
      summarise(
        Avg_Steps = mean(TotalSteps),
        Avg_Distance = mean(TotalDistance),
        Avg_TrackedDistance = mean(TrackerDistance),
        Avg_LoggedActivityDistance = mean(LoggedActivitiesDistance),
        Avg_VeryActiveDistance = mean(VeryActiveDistance),
        Avg_ModeratelyActiveDistance = mean(ModeratelyActiveDistance),
        Avg_LightActiveDistance = mean(LightActiveDistance),
        Avg_SedentaryActiveDistance = mean(SedentaryActiveDistance),
        Avg_Calories = mean(Calories)
    )
  
  write.csv(averages_per_athlete, "customer_averages.csv", row.names = FALSE)
  
  print(head(averages_per_athlete, 5))
}


# line plot function 
line_plot <- function(df, x_col, y_col){
  ggplot (data = df) +
    geom_line(mapping = aes(x= .data[[x_col]] , y= .data[[y_col]] )) +
    labs(title = paste(x_col, "and", y_col, "relationsip"))
}

```



```{r}
dailyActivity_merged_df <-dfs[["dailyActivity_merged_df"]]
str(dailyActivity_merged_df)

# we'll have a look at all unique value in if non of them is repeated
# change ActivityDate from character to datetime
# Assuming TotalSteps is cadence we'll see the average length of a step per person
# See if TotalDistance and TrackerDistance distance record the same data
# Calculate average TotalDistance, TrackerDistance, VeryActiveDistance, 
# ModeratelyActiveDistance, LightActiveDistance, SedentaryActiveDistance,
# Average calories lost per day
```

Check for missing values in dailyActivity_merged_df
```{r}
missing_value(dailyActivity_merged_df)
```

check how many customers are we dealing with
```{r}
# call function on dailyActivity_merged_df
unique_value(dailyActivity_merged_df, "Id")
```

# see the number of character in each character of the ActivityDate column 
# since we've already seen there are inconsistencies in the ActivityDate, -->
# let's see if there are some date characters saved with hrs,min,and secs

```{r}
# see if there is uniformity in the Activity date columns
N_unique_char(dailyActivity_merged_df, "ActivityDate")
```
We have different datatypes let's see if this will affect how changing the datatype of ActivityDate

```{r}
# see if there is uniformity in the Activity date columns
N_unique_char(dailyActivity_merged_df, "ActivityDate")
```

```{r}
# call change_to_date on dailyActivity_merged_df
dailyActivity_merged_df <- change_to_date(dailyActivity_merged_df, "ActivityDate")
```

```{r}
# call identical_columns on dailyActivity_merged_df
identical_columns(dailyActivity_merged_df, "TotalDistance", "TrackerDistance" )
```

```{r}
averages(dailyActivity_merged_df)
```

```{r}
# call function on dailyActivity_merged_df 
line_plot(df = dailyActivity_merged_df, x_col= "Calories", y_col = "TotalDistance")
```
There is a positive correlation between Calories and TotalDistance the is 


## Let's get to see heartrate_seconds_merged_df

```{r}
heartrate_seconds_merged_df <- dfs[["heartrate_seconds_merged_df"]]
str(heartrate_seconds_merged_df)

# Check if the unique Ids are similar to the ones in dailyActivity_merged_df
# change time column to datetime
# see the average heart rate per unique id, see the correlation between the average heart rate and calories lost
# see if there is any negative hr values
```

```{r}
#Check for missing values in heartrate_seconds_merged_df
missing_value(heartrate_seconds_merged_df)
```





